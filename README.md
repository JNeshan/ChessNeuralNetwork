"Why should I plan and solidify logic rules when I can make my 6th unspoken rule that actually conflicts with half the other rules?" - dipshit

This file is now a project journal because trying to store all the assumed logic in your knoggin after not touching it for a week has already created to many very tedious inconsistencies. The layers all depend on ignorant and general functions with consistent basic logic. This is most notably given by the tensor class. The optimizer technically falls under this, but it only is called on for one function, which also applies logic that is already utilized by the tensor class. So overall, the tensor class needs to have a consistent design set and the layers need to
follow the rules set by tensor, not the other way. The first big complication was due to the cudnn descriptors always requiring 4 input dimensions. The original constructor simply set dimensions to the passed dim as long as the values were positive. If a layer doesn't know the number of dimensions its input and/or output are, padding the dimension vector allows the descriptor calls to use the four indices of dimension for its dimensions. This is also assuming that the highest order dimension is the first indice of dimensions and exclusively represents batches (or each filter for filters but its basically a batch of filters so like same thing), the next features, and the next two filter dimensions. Padding the lower powers ensures that size is the same with or without padding which will always be the cause since 1^n = 1 for any real n.
Since dimensions stores the dimensions in the same order as the descriptor, indicing from left to right on the respective arguments will always work so long as all tensors involved are at most 4 dimensional, which will always be the case for this project. Even if I were to add a layer that required a higher dimensional input, it would be expecting that higher dimensional input, which tensor can already handle since it has no upper limit on how many dimensions it can hold (if you count crashing as not holding then its actually 2,147,483,647 but I'm not sure we've found a use for good ol 2,147,483,648 yet). 


 Tensor will now always pad out dimensions to always be 4 elements, which the number of dimensions stored in int n. dimensions[0] always represents the highest order dimension, which is always batches and descends from there. 1 is appended to the end of dimensions until it is at least size 4. The constructor and reshape both take an argument that n, which represents the number of dimensions representing this Tensor, copies. Since dimensions is always at least size 4, size will not be equivalent to n if padding occured. So taking it as an argument is the best option. Having said all this, I'm not actually certain that n is necessary at all outside of quick input validation checks. It'll stay until its deemed useless. All the constructors and copies should perform all operations correctly. Tensor should be fully featured outside of actually getting its starting data.

 The optimizer class and its gradient adjustment should be functional, still needs proper cuda error handling for its custom kernel though.

 Due to recent revelation that running the network in parallel as is optimal would cause multiple forward calls, so storing the tensors needed for backpropagation and training in the layer will not work. Instead the superclass defines a forward and backwards cache struct. The forward cache struct is returned with the output as a pair so that instance of the layers owner can store the data relevant to their run Only the layer original layer that returned it. This needs to be passed back to the backward function at backpropagation to use for gradient calculation just like with the member variables. The backwards function needs to perform its functions and create a BackwardCache object, containing all the Tensors that are changed in training and their corresponding gradient. This is stored as a pair of tensor vector, with one being the main tensors and the other their corresponding gradients at the same vector index as their match. The layers owner will again hold on to each one of these back caches and when training begins will back a vector and its corresponding gradient to the optimizer and continue for every layers backwards cache. Since activation functions don't store permanent vectors, their backwards cache is just a pair of empty vectors.
 
 Because of this change the layers are currently in hell, since changes to forward and backwards definition affects every single layer, and the removal of member variable tensors requires some code be fixed.z